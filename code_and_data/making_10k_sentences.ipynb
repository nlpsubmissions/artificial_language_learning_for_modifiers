{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = PreTrainedTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True,return_offsets_mapping = True, max_length=512,truncate=True,add_special_tokens=False,return_token_type_ids=False,return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = {k: v for k, v in sorted(tokenizer_bert.vocab.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21719"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "for item in vocab_sorted.items():\n",
    "    if re.match('[a-z]{2,}$',item[0]):\n",
    "        words.append(item[0])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "adjs = []\n",
    "for ix,word in enumerate(words):\n",
    "    if nlp(word)[0].pos_ == 'NOUN' and len(nouns) < 1000:\n",
    "        nouns.append(nlp(word)[0].text)\n",
    "    elif nlp(word)[0].pos_ == 'ADJ' and len(adjs) < 2000:\n",
    "        adjs.append(nlp(word)[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding gradable adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import textacy\n",
    "import textacy.datasets\n",
    "cw = textacy.datasets.CapitolWords()\n",
    "cw.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_encountered = []\n",
    "unique_adjectives_encountered = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text,record in cw.records():\n",
    "    processed = nlp(text)\n",
    "    \n",
    "    adjectives_encountered += [token for token in processed if token.text in adjs]\n",
    "    \n",
    "    for token in processed:\n",
    "        if token.text in adjs:\n",
    "            unique_adjectives_encountered |= set([token.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312797, 1459)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjectives_encountered),len(unique_adjectives_encountered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradable = defaultdict(int)\n",
    "non_gradable = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = ['somewhat','very','really','extremely','rather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in adjectives_encountered:\n",
    "    if len([x for x in adj.children if x.text in modifiers])>0:\n",
    "        gradable[adj.text] += 1\n",
    "    else:\n",
    "        non_gradable[adj.text]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in unique_adjectives_encountered:\n",
    "    toAdd = []\n",
    "\n",
    "    toAdd.append(gradable[adj])\n",
    "    toAdd.append(non_gradable[adj])\n",
    "    combined[adj] = toAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = defaultdict(list)\n",
    "for adj in combined:\n",
    "    occurences = sum(combined[adj])\n",
    "    gradability_score = round(float((combined[adj][0])/occurences) * 100, 3)\n",
    "    if occurences > 100 and gradability_score > 0.5:\n",
    "        adjs[adj] = gradability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = [k for k, v in sorted(adjs.items(), key=lambda item: item[1],reverse=True)][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gradable_adjectives.txt', 'w') as f:\n",
    "    for item in adjs:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for noun in nouns:\n",
    "    for adj in adjs:\n",
    "        sentences.append('The '+noun+' is '+adj+'.')\n",
    "        sentences.append('The '+noun+' are '+adj+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The time is simple.',\n",
       " 'The time are simple.',\n",
       " 'The time is disappointed.',\n",
       " 'The time are disappointed.',\n",
       " 'The time is difficult.',\n",
       " 'The time are difficult.',\n",
       " 'The time is helpful.',\n",
       " 'The time are helpful.',\n",
       " 'The time is brief.',\n",
       " 'The time are brief.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by GPT perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import GPT2LMHeadModel, GPT2Tokenizer\n",
    "device = torch.device('cuda:0')\n",
    "model_id = 'gpt2'\n",
    "model_gpt = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer_gpt = GPT2Tokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gpt(sentence):\n",
    "    tokens = [\"[CLS]\"] + tokenizer_gpt.tokenize(sentence)\n",
    "    tokens_ids = tokenizer_gpt.convert_tokens_to_ids(tokens)\n",
    "    tokens_ids = torch.tensor([tokens_ids,], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_gpt(tokens_ids, lm_labels=tokens_ids)\n",
    "        log_likelihood = outputs.item()\n",
    "    return np.exp(log_likelihood) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {}\n",
    "for sentence in sentences:\n",
    "    pairs[sentence] = process_gpt(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158400</th>\n",
       "      <td>The reason is simple.</td>\n",
       "      <td>32.092901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216000</th>\n",
       "      <td>The answer is simple.</td>\n",
       "      <td>33.160138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230401</th>\n",
       "      <td>The rules are simple.</td>\n",
       "      <td>35.773233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126000</th>\n",
       "      <td>The plan is simple.</td>\n",
       "      <td>36.188385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102800</th>\n",
       "      <td>The idea is simple.</td>\n",
       "      <td>37.175624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36899</th>\n",
       "      <td>The wasn are richest.</td>\n",
       "      <td>18833.300436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116693</th>\n",
       "      <td>The wouldn are rural.</td>\n",
       "      <td>19602.368611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37081</th>\n",
       "      <td>The wasn are junior.</td>\n",
       "      <td>20574.691978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37093</th>\n",
       "      <td>The wasn are rural.</td>\n",
       "      <td>21252.049206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37199</th>\n",
       "      <td>The wasn are initial.</td>\n",
       "      <td>21483.724473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentence    perplexity\n",
       "158400  The reason is simple.     32.092901\n",
       "216000  The answer is simple.     33.160138\n",
       "230401  The rules are simple.     35.773233\n",
       "126000    The plan is simple.     36.188385\n",
       "102800    The idea is simple.     37.175624\n",
       "...                       ...           ...\n",
       "36899   The wasn are richest.  18833.300436\n",
       "116693  The wouldn are rural.  19602.368611\n",
       "37081    The wasn are junior.  20574.691978\n",
       "37093     The wasn are rural.  21252.049206\n",
       "37199   The wasn are initial.  21483.724473\n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(pairs, orient='index').reset_index()\n",
    "df = df.rename(columns={\"index\": \"sentence\", 0: \"perplexity\"})\n",
    "df.sort_values(by='perplexity', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='perplexity', ascending=True).to_csv('/home/lisa/hobbies/modifiers_all.csv')\n",
    "df.sort_values(by='perplexity', ascending=True).head(10000).to_csv('/home/lisa/hobbies/modifiers_top10k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing negative vs positive sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k = df.sort_values(by='perplexity', ascending=True).head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_10k = []\n",
    "neg_10k = []\n",
    "for sentence in ten_k['sentence'].values:\n",
    "    words = sentence.split(' ')\n",
    "    aff = ' '.join(words[:3]+['[MASK]']+words[3:])    \n",
    "    if words[2] == 'is':\n",
    "        neg = ' '.join(words[:2]+[\"isn't [MASK]\"]+words[3:])\n",
    "    else:\n",
    "        neg = ' '.join(words[:2]+[\"aren't [MASK]\"]+words[3:])\n",
    "    pos_10k.append(aff)\n",
    "    neg_10k.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('10k_aff.txt', 'a') as f:\n",
    "    for sentence in pos_10k:\n",
    "        f.write(sentence+'\\n')\n",
    "        \n",
    "with open('10k_neg.txt', 'a') as f:\n",
    "    for sentence in neg_10k:\n",
    "        f.write(sentence+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
